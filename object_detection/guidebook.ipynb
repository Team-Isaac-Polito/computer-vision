{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roboflow Dataset Preprocessing and General Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is twofold: firstly, to provide an overview of the structure of the Roboflow dataset, and secondly, to offer information regarding certain files and preprocessing cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Directory Structure\n",
    "We expect the directory structure to be in this format\n",
    "\n",
    "```\n",
    ".\n",
    "└── dataset/\n",
    "    ├── train/\n",
    "    │   ├── images/\n",
    "    │   └── labels/\n",
    "    ├── valid/\n",
    "    │   ├── images/\n",
    "    │   └── labels/\n",
    "    ├── test/\n",
    "    │   ├── images/\n",
    "    │   └── labels/\n",
    "    └── data.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This structure is essential for training the ultralytics YOLO model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *data.yaml* Structure\n",
    "\n",
    "*data.yaml* is a configuration file that contains some basic information about the dataset. The basic structure is:\n",
    "\n",
    "```yaml\n",
    "train: ../train/images\n",
    "val: ../valid/images\n",
    "test: ../test/images\n",
    "\n",
    "nc: 5\n",
    "names: ['fire_extinguisher', 'baby_face', 'hard_hat', 'backpack', 'propane_tank']\n",
    "```\n",
    "\n",
    "- First three lines are constant, specifying the train, val and test folder positions.\n",
    "- nc means number of classes (the class ids are directly related to nc)\n",
    "- names indicate the names of the classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Structure of *labels* Folder\n",
    "\n",
    "The *labels* folder stores class id of the box in the first digit and the properties of the boxes for the following digits. For example:\n",
    "\n",
    "```\n",
    "0 0.34698 0.49266666666666664 0.34998 0.8866666666666667\n",
    "0 0.61648 0.49896 0.2253 0.8895466666666666\n",
    "```\n",
    "\n",
    "The label above means that the image file it corresponds to has two boxes, because there are two lines. The line format usually follows the pattern [class x_center y_center width height]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Dataset\n",
    "This section is intended to provide some quick code snippets that may be of use to someone pre-processing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This section is only useful if you want to pre-process a chunk of data at the same time. Otherwise, use [roboflow](https://blog.roboflow.com/getting-started-with-roboflow/) to pre-process the data you want to add. **Skip this section if you are not adding or pre-processing data for your training data set.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the dirname of the *labels* folder we aim to modify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DIR = \"archive\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the files and create `lines` variable to rewrite the label classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_class_id = '1' # class id to be replaced\n",
    "new_class_id = '4' # new class id\n",
    "\n",
    "for subfolder in [\"train\", \"valid\"]:\n",
    "    dirname = f\"{DIR}/{subfolder}/labels\"\n",
    "    filenames = os.listdir(dirname)\n",
    "    for filename in filenames:\n",
    "        path = os.path.join(dirname, filename)\n",
    "        with open(path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        with open(path, 'w') as file:\n",
    "            for line in lines:\n",
    "                if line.startswith(prev_class_id):\n",
    "                    line = new_class_id + line[1:]\n",
    "                file.write(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn segments into box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subfolder in [\"train\", \"valid\"]:\n",
    "    dirname = f\"{DIR}/{subfolder}/labels\"\n",
    "    filenames = os.listdir(dirname)\n",
    "    for filename in filenames:\n",
    "        path = os.path.join(dirname, filename)\n",
    "        with open(path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        with open(path, 'w') as file:\n",
    "            for line in lines:\n",
    "                if len(line.split()) > 5:\n",
    "                    x = []\n",
    "                    y = []\n",
    "                    print(line)\n",
    "                    for i in range(1, len(line.split()), 2):\n",
    "                        x.append(float(line.split()[i]))\n",
    "                        y.append(float(line.split()[i+1]))\n",
    "                    line = line[0] + ' ' + str((min(x) + max(x)) / 2) + ' ' + str((min(y) + max(y)) / 2) + ' ' + str(max(x) - min(x)) + ' ' + str(max(y) - min(y))\n",
    "                    print(line)\n",
    "                file.write(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the lines with unwanted class ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_id = '9 ' # class id to be removed\n",
    "\n",
    "for subfolder in [\"train\", \"valid\"]:\n",
    "    dirname = f\"{DIR}/{subfolder}/labels\"\n",
    "    filenames = os.listdir(dirname)\n",
    "    for filename in filenames:\n",
    "        path = os.path.join(dirname, filename)\n",
    "        with open(path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        with open(path, 'w') as file:\n",
    "            for line in lines:\n",
    "                if line[:2] != class_id:\n",
    "                    file.write(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the files with unwanted class ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_id = '0 ' # class id to be removed\n",
    "\n",
    "for subfolder in [\"train\", \"valid\"]:\n",
    "    imgs = f\"{DIR}/{subfolder}/images\"\n",
    "    labels = f\"{DIR}/{subfolder}/labels\"\n",
    "    for img_name, label_name in zip(os.listdir(imgs), os.listdir(labels)):\n",
    "        path = os.path.join(labels, label_name)\n",
    "        with open(path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        if any([line[:2] == class_id for line in lines]): # Delete if any line starts with class_id\n",
    "            os.remove(os.path.join(imgs, img_name))\n",
    "            os.remove(os.path.join(labels, label_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse each class id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subfolder in [\"train\", \"valid\"]:\n",
    "    dirname = f\"{DIR}/{subfolder}/labels\"\n",
    "    filenames = os.listdir(dirname)\n",
    "\n",
    "    class_ids = ['0', '1', '2', '3', '4']\n",
    "    count = [0] * len(class_ids)\n",
    "    empty = 0\n",
    "    for filename in filenames:\n",
    "        path = os.path.join(dirname, filename)\n",
    "        with open(path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            if len(lines) == 0:\n",
    "                empty += 1\n",
    "            for line in lines:\n",
    "                if line[0] == class_ids[0]:\n",
    "                    count[0] += 1\n",
    "                    break\n",
    "                elif line[0] == class_ids[1]:\n",
    "                    count[1] += 1\n",
    "                    break\n",
    "                elif line[0] == class_ids[2]:\n",
    "                    count[2] += 1\n",
    "                    break\n",
    "                elif line[0] == class_ids[3]:\n",
    "                    count[3] += 1\n",
    "                    break\n",
    "                elif line[0] == class_ids[4]:\n",
    "                    count[4] += 1\n",
    "                    break\n",
    "\n",
    "    # Print the results\n",
    "    print(f'{subfolder} folder:', end='\\n\\n')\n",
    "    for ci, c in zip(class_ids, count):\n",
    "        print(f'Class ID {ci}: {c} instances', end='\\n\\n')\n",
    "    print(f'Empty files: {empty} instances', end='\\n\\n')\n",
    "    \n",
    "    if subfolder == \"train\":\n",
    "        print('-------------------------', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move from train to valid and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = \"archive\" # Directory to move files from/to\n",
    "class_id = '0 ' # class id to be replaced\n",
    "no_class = False # True if you want to move files with no class, False if you want to move files with a specific class\n",
    "\n",
    "src = \"train\" # Source folder to move files from\n",
    "des = \"valid\" # Destination folder to move files to\n",
    "\n",
    "imgs = f\"{DIR}/{src}/images\"\n",
    "labels = f\"{DIR}/{src}/labels\"\n",
    "\n",
    "c = 0 # Counter to track the number of files processed\n",
    "for img_name, label_name in zip(os.listdir(imgs), os.listdir(labels)):\n",
    "    path = os.path.join(labels, label_name)\n",
    "    with open(path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    if no_class:\n",
    "        if len(lines) == 0 and c < 0:\n",
    "            os.rename(os.path.join(imgs, img_name), os.path.join(f\"{DIR}/{des}/images\", img_name))\n",
    "            os.rename(os.path.join(labels, label_name), os.path.join(f\"{DIR}/{des}/labels\", label_name))\n",
    "            c += 1\n",
    "    elif any([line[:2] == class_id for line in lines]) and c < 300:\n",
    "        os.rename(os.path.join(imgs, img_name), os.path.join(f\"{DIR}/{des}/images\", img_name))\n",
    "        os.rename(os.path.join(labels, label_name), os.path.join(f\"{DIR}/{des}/labels\", label_name))\n",
    "        c += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [The last title](#preprocessing-dataset) is primarily concerned with providing concise code snippets for specific preprocessing operations, with the aim of either rectifying existing issues or implementing additional features as required.\n",
    "- The main dataset that we use for training the model is on Dropbox.\n",
    "- There are also other datasets that we can merge with our main dataset. Here is the [link](https://universe.roboflow.com/) to find other datasets to pre-process and merge with our main dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
