{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roboflow Dataset Preprocessing and General Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is twofold: firstly, to provide an overview of the structure of the Roboflow dataset, and secondly, to offer information regarding certain files and preprocessing cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Directory Structure\n",
    "We expect the directory structure to be in this format\n",
    "\n",
    "```\n",
    ".\n",
    "└── Dataset/Directory/\n",
    "    ├── README_files/\n",
    "    │   └── ...\n",
    "    ├── test/\n",
    "    │   ├── images/\n",
    "    │   │   ├── 38.png\n",
    "    │   │   └── ...\n",
    "    │   └── labels/\n",
    "    │   │   ├── 38_png.txt\n",
    "    │   │   └── ...\n",
    "    ├── train/\n",
    "    │   ├── images/\n",
    "    │   │   ├── 1.png\n",
    "    │   │   └── ...\n",
    "    │   └── labels/\n",
    "    │   │   ├── 1_png.txt\n",
    "    │   │   └── ...\n",
    "    ├── valid/\n",
    "    │   ├── images/\n",
    "    │   │   ├── 15.png\n",
    "    │   │   └── ...\n",
    "    │   └── labels/\n",
    "    │   │   ├── 15_png.txt\n",
    "    │   │   └── ...\n",
    "    └── data.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This structure is essential for training the ultralytics YOLO model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *data.yaml* Structure\n",
    "\n",
    "*data.yaml* is a configuration file that contains some basic information about the dataset. The basic structure is:\n",
    "\n",
    "```yaml\n",
    "train: ../train/images\n",
    "val: ../valid/images\n",
    "test: ../test/images\n",
    "\n",
    "nc: 5\n",
    "names: ['fire_extinguisher', 'baby_face', 'hard_hat', 'backpack', 'propane_tank']\n",
    "```\n",
    "\n",
    "- First three lines are constant, specifying the train, val and test folder positions.\n",
    "- nc means number of classes (the class ids are directly related to nc)\n",
    "- names indicate the names of the classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no need to change this as we only have 5 classes and have no intention of adding more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Structure of *labels* Folder\n",
    "\n",
    "The *labels* folder stores class id of the box in the first digit and the properties of the boxes for the following digits. For example:\n",
    "\n",
    "`0 0.46015625 0.409375 0.7890625 0.6875`\n",
    "\n",
    "The text above means that the image with the same name as the text file has only one box since there is only one line and it has a class ID of 0 (fire_extinguisher). The remaining numbers represent the properties of the box (centerx, centery, width and height, respectively)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the dirname of the *labels* folder we aim to modify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dirname = \"archive/valid/labels\" # validation labels\n",
    "filenames = os.listdir(dirname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the files and create `lines` variable to rewrite the label classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_class_id = '0' # class id to be replaced\n",
    "new_class_id = '4' # new class id\n",
    "\n",
    "for filename in filenames:\n",
    "    path = os.path.join(dirname, filename)\n",
    "    with open(path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    with open(path, 'w') as file:\n",
    "        for line in lines:\n",
    "            if line.startswith(prev_class_id):\n",
    "                line = new_class_id + line[1:]\n",
    "            file.write(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn segments into box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in filenames:\n",
    "    path = os.path.join(dirname, filename)\n",
    "    with open(path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    with open(path, 'w') as file:\n",
    "        for line in lines:\n",
    "            if len(line.split()) > 5:\n",
    "                x = []\n",
    "                y = []\n",
    "                print(line)\n",
    "                for i in range(1, len(line.split()), 2):\n",
    "                    x.append(float(line.split()[i]))\n",
    "                    y.append(float(line.split()[i+1]))\n",
    "                line = line[0] + ' ' + str((min(x) + max(x)) / 2) + ' ' + str((min(y) + max(y)) / 2) + ' ' + str(max(x) - min(x)) + ' ' + str(max(y) - min(y))\n",
    "                print(line)\n",
    "            file.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the lines with unwanted class ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_id = '9 ' # class id to be removed\n",
    "\n",
    "for filename in filenames:\n",
    "    path = os.path.join(dirname, filename)\n",
    "    with open(path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    with open(path, 'w') as file:\n",
    "        for line in lines:\n",
    "            if line[:2] == class_id:\n",
    "                file.write(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the files with unwanted class ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_id = '0 ' # class id to be removed\n",
    "\n",
    "for subfolder in [\"train\", \"valid\"]:\n",
    "    imgs = f\"yolo2.v2i.yolov11/{subfolder}/images\"\n",
    "    labels = f\"yolo2.v2i.yolov11/{subfolder}/labels\"\n",
    "    for img_name, label_name in zip(os.listdir(imgs), os.listdir(labels)):\n",
    "        path = os.path.join(labels, label_name)\n",
    "        with open(path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "        if any([line[:2] == class_id for line in lines]): # Delete if any line starts with class_id\n",
    "            os.remove(os.path.join(imgs, img_name))\n",
    "            os.remove(os.path.join(labels, label_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move from train to valid and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_id = '1 ' # class id to be replaced\n",
    "no_class = False\n",
    "\n",
    "src = \"valid\"\n",
    "des = \"train\"\n",
    "\n",
    "imgs = f\"archive/{src}/images\"\n",
    "labels = f\"archive/{src}/labels\"\n",
    "c = 0 # Counter to track the number of files processed\n",
    "for img_name, label_name in zip(os.listdir(imgs), os.listdir(labels)):\n",
    "    path = os.path.join(labels, label_name)\n",
    "    with open(path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    if no_class:\n",
    "        if len(lines) == 0 and c < 0:\n",
    "            os.rename(os.path.join(imgs, img_name), os.path.join(f\"archive/{des}/images\", img_name))\n",
    "            os.rename(os.path.join(labels, label_name), os.path.join(f\"archive/{des}/labels\", label_name))\n",
    "            c += 1\n",
    "    elif any([line[:2] == class_id for line in lines]) and c < 0:\n",
    "        os.rename(os.path.join(imgs, img_name), os.path.join(f\"archive/{des}/images\", img_name))\n",
    "        os.rename(os.path.join(labels, label_name), os.path.join(f\"archive/{des}/labels\", label_name))\n",
    "        c += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse each class id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class ID 0: 1109 instances\n",
      "Class ID 1: 176 instances\n",
      "Class ID 2: 1347 instances\n",
      "Class ID 3: 185 instances\n",
      "Class ID 4: 184 instances\n",
      "Empty files: 401 instances\n"
     ]
    }
   ],
   "source": [
    "class_ids = ['0', '1', '2', '3', '4']\n",
    "count = [0] * len(class_ids)\n",
    "empty = 0\n",
    "for filename in filenames:\n",
    "    path = os.path.join(dirname, filename)\n",
    "    with open(path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        if len(lines) == 0:\n",
    "            empty += 1\n",
    "        for line in lines:\n",
    "            if line[0] == class_ids[0]:\n",
    "                count[0] += 1\n",
    "                break\n",
    "            elif line[0] == class_ids[1]:\n",
    "                count[1] += 1\n",
    "                break\n",
    "            elif line[0] == class_ids[2]:\n",
    "                count[2] += 1\n",
    "                break\n",
    "            elif line[0] == class_ids[3]:\n",
    "                count[3] += 1\n",
    "                break\n",
    "            elif line[0] == class_ids[4]:\n",
    "                count[4] += 1\n",
    "                break\n",
    "\n",
    "for ci, c in zip(class_ids, count):\n",
    "    print(f'Class ID {ci}: {c} instances')\n",
    "print(f'Empty files: {empty} instances')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [The last title](#preprocessing-dataset) is primarily concerned with providing concise code snippets for specific preprocessing operations, with the aim of either rectifying existing issues or implementing additional features as required.\n",
    "- Here's the [link](https://universe.roboflow.com/) to find the datasets for preprocessing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
