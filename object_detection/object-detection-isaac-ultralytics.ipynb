{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline for Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages and Define Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T10:48:20.696858Z",
     "iopub.status.busy": "2025-03-06T10:48:20.696531Z",
     "iopub.status.idle": "2025-03-06T10:48:20.701267Z",
     "shell.execute_reply": "2025-03-06T10:48:20.700260Z",
     "shell.execute_reply.started": "2025-03-06T10:48:20.696837Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "TRAIN = 0 # 1 for training, 0 for inference \n",
    "MODEL_PATH = \"yolo11n.pt\" if TRAIN else \"best.pt\" # path to dataset, not available in this repo (a bit too large)\n",
    "DATA_PATH = \"robocup-od-dataset/data.yaml\"\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "IMAGE_SIZE = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-03-06T10:30:11.353912Z",
     "iopub.status.busy": "2025-03-06T10:30:11.353414Z",
     "iopub.status.idle": "2025-03-06T10:41:45.970818Z",
     "shell.execute_reply": "2025-03-06T10:41:45.969852Z",
     "shell.execute_reply.started": "2025-03-06T10:30:11.353870Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "# Train the model\n",
    "if TRAIN:\n",
    "    results = model.train(\n",
    "        data=DATA_PATH,\n",
    "        epochs=EPOCHS,\n",
    "        batch=BATCH_SIZE,\n",
    "        imgsz=IMAGE_SIZE,\n",
    "        device='cuda',\n",
    "        augment=True,\n",
    "        flipud=0.5,    # Probability for vertical flip\n",
    "        fliplr=0.5,    # Probability for horizontal flip\n",
    "        hsv_h=0.25,    # Adjust hue\n",
    "        hsv_s=0.7,     # Adjust saturation\n",
    "        hsv_v=0.4,     # Adjust value\n",
    "        mosaic=1.0,    # Probability for mosaic augmentation\n",
    "        mixup=0.0      # Probability for mixup augmentation\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T10:41:45.973069Z",
     "iopub.status.busy": "2025-03-06T10:41:45.972683Z",
     "iopub.status.idle": "2025-03-06T10:41:45.979038Z",
     "shell.execute_reply": "2025-03-06T10:41:45.978133Z",
     "shell.execute_reply.started": "2025-03-06T10:41:45.973019Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    for k,v in results.results_dict.items():\n",
    "        print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation and Test Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T10:41:45.980366Z",
     "iopub.status.busy": "2025-03-06T10:41:45.980078Z",
     "iopub.status.idle": "2025-03-06T10:41:57.451471Z",
     "shell.execute_reply": "2025-03-06T10:41:57.449681Z",
     "shell.execute_reply.started": "2025-03-06T10:41:45.980335Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    results = model.val(\n",
    "        data=DATA_PATH,\n",
    "        epochs=EPOCHS,\n",
    "        batch=BATCH_SIZE,\n",
    "        imgsz=IMAGE_SIZE,\n",
    "        device='cuda'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T10:48:23.878295Z",
     "iopub.status.busy": "2025-03-06T10:48:23.877903Z",
     "iopub.status.idle": "2025-03-06T10:48:24.521592Z",
     "shell.execute_reply": "2025-03-06T10:48:24.520765Z",
     "shell.execute_reply.started": "2025-03-06T10:48:23.878263Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\yunus\\Documents\\hello-docker\\computer-vision\\object_detection\\test\\iou_png_jpg.rf.c1b6bfc14e8368b5e6791d48f4683263.jpg: 512x512 1 propane_tank, 340.8ms\n",
      "Speed: 2.5ms preprocess, 340.8ms inference, 3.2ms postprocess per image at shape (1, 3, 512, 512)\n",
      "\n",
      "image 1/1 c:\\Users\\yunus\\Documents\\hello-docker\\computer-vision\\object_detection\\test\\000031_jpg.rf.59838b35cd4572fe1780ece1c85b504f.jpg: 352x512 3 hard_hats, 293.8ms\n",
      "Speed: 1.8ms preprocess, 293.8ms inference, 2.5ms postprocess per image at shape (1, 3, 352, 512)\n",
      "\n",
      "image 1/1 c:\\Users\\yunus\\Documents\\hello-docker\\computer-vision\\object_detection\\test\\000001_jpg.rf.fddb09e33a544e332617f8ceb53ee805.jpg: 384x512 2 hard_hats, 325.0ms\n",
      "Speed: 1.5ms preprocess, 325.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 512)\n",
      "\n",
      "image 1/1 c:\\Users\\yunus\\Documents\\hello-docker\\computer-vision\\object_detection\\test\\2542_png.rf.bdc3ab9dc8a07450537bc68b8003a130.jpg: 512x512 (no detections), 128.7ms\n",
      "Speed: 1.9ms preprocess, 128.7ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 512)\n",
      "\n",
      "image 1/1 c:\\Users\\yunus\\Documents\\hello-docker\\computer-vision\\object_detection\\test\\0001_jpg.rf.6c5ce1a38701528197509b823a663f46.jpg: 512x512 1 fire_extinguisher, 200.7ms\n",
      "Speed: 2.0ms preprocess, 200.7ms inference, 2.5ms postprocess per image at shape (1, 3, 512, 512)\n",
      "\n",
      "image 1/1 c:\\Users\\yunus\\Documents\\hello-docker\\computer-vision\\object_detection\\test\\2038_png.rf.535282e426a6306f823f2ef828c26c91.jpg: 512x512 (no detections), 187.9ms\n",
      "Speed: 1.7ms preprocess, 187.9ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 512)\n",
      "\n",
      "image 1/1 c:\\Users\\yunus\\Documents\\hello-docker\\computer-vision\\object_detection\\test\\images-6-_png_jpg.rf.69c6a415ae006e1de527108b45f54e7a.jpg: 512x512 1 fire_extinguisher, 2 propane_tanks, 151.3ms\n",
      "Speed: 15.2ms preprocess, 151.3ms inference, 2.8ms postprocess per image at shape (1, 3, 512, 512)\n",
      "\n",
      "image 1/1 c:\\Users\\yunus\\Documents\\hello-docker\\computer-vision\\object_detection\\test\\3398_png.rf.9cf77be29973d8abd060eb6595d8d51e.jpg: 512x512 1 baby_face, 175.2ms\n",
      "Speed: 3.5ms preprocess, 175.2ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 512)\n",
      "\n",
      "image 1/1 c:\\Users\\yunus\\Documents\\hello-docker\\computer-vision\\object_detection\\test\\Stay-Stylish-dan-Tertata-dengan-Gyeongnam-Travel-Backpack-di-Setiap-Perjalanan-_jpeg.rf.0596e405256dae7a8127284b8db0a76d.jpg: 512x512 2 backpacks, 179.6ms\n",
      "Speed: 6.2ms preprocess, 179.6ms inference, 3.0ms postprocess per image at shape (1, 3, 512, 512)\n",
      "\n",
      "image 1/1 c:\\Users\\yunus\\Documents\\hello-docker\\computer-vision\\object_detection\\test\\-_-24-_jpg.rf.2e6beeddf8c366829137ffb57fbaf5b3.jpg: 512x512 2 fire_extinguishers, 146.9ms\n",
      "Speed: 2.7ms preprocess, 146.9ms inference, 3.3ms postprocess per image at shape (1, 3, 512, 512)\n",
      "\n",
      "image 1/1 c:\\Users\\yunus\\Documents\\hello-docker\\computer-vision\\object_detection\\test\\4408_png.rf.8d9327f1e116fc39ed9c65608d11a59f.jpg: 512x512 (no detections), 235.9ms\n",
      "Speed: 6.6ms preprocess, 235.9ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 512)\n",
      "\n",
      "image 1/1 c:\\Users\\yunus\\Documents\\hello-docker\\computer-vision\\object_detection\\test\\download-10-_jpeg.rf.9c658f80ec2602d68b56bf2d57391c7d.jpg: 512x512 2 backpacks, 207.6ms\n",
      "Speed: 4.4ms preprocess, 207.6ms inference, 2.7ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "dirname = \"test\"\n",
    "filenames = os.listdir(dirname)\n",
    "random.shuffle(filenames)\n",
    "\n",
    "for filename in filenames:\n",
    "    path = os.path.join(dirname, filename)\n",
    "    results = model.predict(path)\n",
    "    for result in results:\n",
    "        result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Adjustments\n",
    "- **Adjust Learning Rate:** Experiment with a different initial learning rate (e.g., `lr0=0.001`) to improve convergence and avoid overshooting optimal weights.\n",
    "- **Class-Specific Training:** Use the `classes` parameter to focus training on specific classes that are underperforming or require prioritization.\n",
    "- **Fine-Tune Augmentation Probabilities:** Adjust the probabilities to test the impact on generalization.\n",
    "- **Hue, Saturation, and Value Adjustment:** Experiment with subtle changes to improve color transformations."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6803274,
     "sourceId": 10940358,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 226097689,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
