{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hazardous Material Sign Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import random\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "The hazmat labels of the RoboCupRescue League are:\n",
    "* explosives\n",
    "* blasting agents\n",
    "* flammable gas\n",
    "* non flammable gas\n",
    "* oxygen\n",
    "* fuel-oil\n",
    "* dangerous-when-wet\n",
    "* flammable-solid\n",
    "* spontaneously-combistible\n",
    "* oxidizer\n",
    "* organic-peroxide\n",
    "* inhalation-hazard\n",
    "* poison\n",
    "* radioactive\n",
    "* corrosive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -n ./dataset/hazmat-placard-image-dataset -d dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get absolute path\n",
    "path = !pwd\n",
    "path = path[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure of the directory\n",
    "```\n",
    ".\n",
    "└── hazmat_detection/\n",
    "    ├── checkpoints/\n",
    "    │   └── ...\n",
    "    ├── dataset/\n",
    "    │   └── HazMat.v16i.yolov11/\n",
    "    │       ├── data.yaml\n",
    "    │       │\n",
    "    │       ├── train/\n",
    "    │       │   ├── images/\n",
    "    │       │   │\n",
    "    │       │   └── labels/\n",
    "    │       │  \n",
    "    │       ├── val/\n",
    "    │       │\n",
    "    │       ├── test/\n",
    "    │       │ \n",
    "    │       └── ...\n",
    "    ├── utils/\n",
    "    │   └── ...\n",
    "    ├── model.ipynb\n",
    "    ├── requirements.txt\n",
    "    ├── train.py\n",
    "    └── test.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check data distribution in the training, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 15 # number of labels\n",
    "classes = range(0, NUM_CLASSES)\n",
    "data = pd.DataFrame()\n",
    "empty = 0 # count number of empty inputs\n",
    "\n",
    "# for each dataset\n",
    "for dataset in [\"train\",\"valid\",\"test\"]:\n",
    "    directory = f\"dataset/HazMat.v16i.yolov11/{dataset}/labels\"\n",
    "    filenames = os.listdir(directory)\n",
    "    classCount = {el: 0 for el in range(0,NUM_CLASSES)}\n",
    "    total = 0\n",
    "    for filename in filenames:\n",
    "        with open(os.path.join(directory, filename), 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            if len(lines) == 0:\n",
    "                empty += 1\n",
    "            else:\n",
    "                for line in lines:\n",
    "                    classCount[int(line.strip().split(\" \")[0])] += 1\n",
    "                    total += 1\n",
    "    # print\n",
    "    values = pd.array(list(classCount.values()))/total\n",
    "    data[dataset] = values.copy()\n",
    "\n",
    "print(f\"There are {empty} empty lines\")\n",
    "# plot distribution of labels in training, validation and test set\n",
    "plt.grid(alpha=0.5)\n",
    "sns.lineplot(data=data)\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xticks(range(0,NUM_CLASSES))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 640 # size for YOLO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"Cuda\")\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    print(\"Cuda not available, use mps\")\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    print(\"Use CPU\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained model\n",
    "model = YOLO(\"./checkpoints/yolo11n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.train(data=f\"{path}/dataset/HazMat.v16i.yolov11/data.yaml\", epochs=20, batch=32, device=device,\n",
    "        imgsz=IMAGE_SIZE,\n",
    "        augment=True,\n",
    "        flipud=0.5,    # Probability for vertical flip\n",
    "        fliplr=0.5,    # Probability for horizontal flip\n",
    "        hsv_h=0.1,    # Adjust hue\n",
    "        hsv_s=0.7,     # Adjust saturation\n",
    "        hsv_v=0.4,     # Adjust value\n",
    "        degrees=180, # randomly rotate -180 to +180\n",
    "        translate=0.2, # translate image horizontally and vertically\n",
    "        scale=0.1, # scale image to simulate different distance\n",
    "        shear=0.1, # mimic image seen from different angle\n",
    "        # perspective=0.1, # perspective transformation\n",
    "        # cos_lr=True, # cosine learning rate scheduler\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.val(\n",
    "        data=f\"{path}/dataset/HazMat.v16i.yolov1/data.yaml\",\n",
    "        epochs=1,\n",
    "        batch=32,\n",
    "        imgsz=IMAGE_SIZE,\n",
    "        device=device\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathTest = f\"{path}/dataset/HazMat.v16i.yolov1/images/test\"\n",
    "filenames = os.listdir(pathTest)\n",
    "random.shuffle(filenames)\n",
    "\n",
    "for filename in filenames:\n",
    "    path = os.path.join(pathTest, filename)\n",
    "    results = model.predict(path)\n",
    "    for result in results:\n",
    "        result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While training, YOLO Ultralytics creates a folder called ```runs``` where you can find the best and last model trained. You can download them and use them as starting point for finetuning, further training and so on."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TeamIsaac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
